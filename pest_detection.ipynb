{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the YOLOv10 model\n",
    "model = YOLO(\"yolov10n.pt\")  # Load the appropriate YOLOv10 model\n",
    "\n",
    "# Example: Train the model using the loaded dataset\n",
    "def train_model(model, train_loader, val_loader, epochs=10, initial_lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()  # Adjust as per YOLOv10 (YOLO models typically use different loss functions)\n",
    "\n",
    "    # To store learning rate history for plotting\n",
    "    lr_history = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass (Make sure the model is expecting images in the correct format)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss (adjust loss computation based on your model)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Store the current learning rate for plotting\n",
    "        lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    # Plot learning rate graph\n",
    "    plt.plot(range(epochs), lr_history, label='Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, epochs=10, initial_lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv10 model\n",
    "model = YOLO(\"yolov10n.pt\")  # Ensure this is the correct model file\n",
    "\n",
    "# Path to the custom dataset YAML file\n",
    "yaml_file = \"/home/dharun/Desktop/pest_detection/Pest_dectection/Custom Dataset After Augmentation/data.yaml\"\n",
    "\n",
    "# Start training using the custom dataset\n",
    "model.train(data=yaml_file, epochs=3, batch=32, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#to check latency\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a COCO-pretrained YOLOv5 model and force it to run on the CPU\n",
    "model = YOLO(\"/home/dharun/Desktop/pest_detection/yolov8.pt\")\n",
    "model.to(\"cpu\")  # Ensure model runs on CPU\n",
    "\n",
    "# Open the video file\n",
    "video_path = '/home/dharun/Desktop/pest_detection/videoplayback.mp4'  # Replace with your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video was successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Couldn't open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Output video setup\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Video codec\n",
    "out = cv2.VideoWriter('output_video.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# List to store latencies\n",
    "latencies = []\n",
    "frame_numbers = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # End of video\n",
    "\n",
    "    frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))  # Get current frame number\n",
    "\n",
    "    # Measure latency for each frame\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    # Run inference on the frame (model inference on CPU)\n",
    "    results = model(frame)  # Inference on the current frame\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    \n",
    "    # Calculate latency (in seconds)\n",
    "    latency = end_time - start_time\n",
    "\n",
    "    # Append latency and frame number for graphing\n",
    "    latencies.append(latency)\n",
    "    frame_numbers.append(frame_number)\n",
    "\n",
    "    # Draw results on the frame\n",
    "    annotated_frame = results[0].plot()  # Annotate frame with detection results\n",
    "\n",
    "    # Write the annotated frame to output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # Optional: Show the annotated frame (for testing purposes)\n",
    "    # cv2.imshow(\"Frame\", annotated_frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Plot the latency graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(frame_numbers, latencies, label=\"Inference Latency\", color='b', marker='o', linestyle='-', markersize=4)\n",
    "plt.title(\"Inference Latency per Frame (CPU)\")\n",
    "plt.xlabel(\"Frame Number\")\n",
    "plt.ylabel(\"Latency (seconds)\")\n",
    "\n",
    "# Dynamically adjust the y-axis based on the observed latencies\n",
    "min_latency = min(latencies)\n",
    "max_latency = max(latencies)\n",
    "\n",
    "# Add a margin of 10% around the min/max latency for better visualization\n",
    "margin = (max_latency - min_latency) * 0.1\n",
    "plt.ylim(min_latency - margin, max_latency + margin)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Add grid and legend\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
